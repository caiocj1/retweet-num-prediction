Word2VecParams:
  vector_size: 256  # size of word embedding
  w2v_epochs: 4

DatasetParams:
  apply_w2v: True
  apply_pca: False  # only works with NoTextMLP, reduces input
  reduced_dims: 5

ModelParams:
  layer_width: 128
  num_layers: 3     # includes input and output layers (must be >= 2)
  dropout: True

TrainingParams:
  num_splits: 10    # number of folds for cross validation
  split_seed: 12345 # seed for reproducibility of results