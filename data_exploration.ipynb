{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import gensim, logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       retweets_count  favorites_count  followers_count  statuses_count  \\\ncount   353969.000000    353969.000000     3.539690e+05    3.539690e+05   \nmean        15.831810        46.655442     2.021548e+04    4.808507e+04   \nstd        241.986723       852.044385     2.598715e+05    1.133854e+05   \nmin          0.000000         0.000000     0.000000e+00    1.000000e+00   \n25%          0.000000         0.000000     1.600000e+02    2.972000e+03   \n50%          1.000000         0.000000     7.260000e+02    1.250100e+04   \n75%          3.000000         1.000000     2.283000e+03    4.352200e+04   \nmax      63674.000000    122591.000000     1.441710e+07    8.183508e+06   \n\n       friends_count       verified     timestamp       TweetID  \ncount  353969.000000  353969.000000  3.539690e+05  3.539690e+05  \nmean     1459.289003       0.030005  1.647004e+12  6.872503e+05  \nstd      2502.933271       0.170602  4.846468e+09  4.175793e+05  \nmin         0.000000       0.000000  1.301178e+12  3.000000e+00  \n25%       214.000000       0.000000  1.647068e+12  3.194490e+05  \n50%       693.000000       0.000000  1.647292e+12  6.719730e+05  \n75%      1804.000000       0.000000  1.647532e+12  1.049644e+06  \nmax    237269.000000       1.000000  1.647727e+12  1.434456e+06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>verified</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>15.831810</td>\n      <td>46.655442</td>\n      <td>2.021548e+04</td>\n      <td>4.808507e+04</td>\n      <td>1459.289003</td>\n      <td>0.030005</td>\n      <td>1.647004e+12</td>\n      <td>6.872503e+05</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>241.986723</td>\n      <td>852.044385</td>\n      <td>2.598715e+05</td>\n      <td>1.133854e+05</td>\n      <td>2502.933271</td>\n      <td>0.170602</td>\n      <td>4.846468e+09</td>\n      <td>4.175793e+05</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.301178e+12</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.600000e+02</td>\n      <td>2.972000e+03</td>\n      <td>214.000000</td>\n      <td>0.000000</td>\n      <td>1.647068e+12</td>\n      <td>3.194490e+05</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.260000e+02</td>\n      <td>1.250100e+04</td>\n      <td>693.000000</td>\n      <td>0.000000</td>\n      <td>1.647292e+12</td>\n      <td>6.719730e+05</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.283000e+03</td>\n      <td>4.352200e+04</td>\n      <td>1804.000000</td>\n      <td>0.000000</td>\n      <td>1.647532e+12</td>\n      <td>1.049644e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>63674.000000</td>\n      <td>122591.000000</td>\n      <td>1.441710e+07</td>\n      <td>8.183508e+06</td>\n      <td>237269.000000</td>\n      <td>1.000000</td>\n      <td>1.647727e+12</td>\n      <td>1.434456e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/evaluation.csv')\n",
    "train_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  retweets_count  \\\n0                 rt refarcir macron ans nom prépare               3   \n1                                          populaire               0   \n2                                faut dégager cinglé               3   \n3  enseignants mettre prescriptions président rép...               0   \n4                         mafieuse oppressive macron               0   \n\n   favorites_count  followers_count  statuses_count  friends_count mentions  \\\n0                0             3682          453535           3628       []   \n1                0               86            1016            284       []   \n2                1             1944           28234           1995       []   \n3                0                1            1072              0       []   \n4                0            13957           25311          10841       []   \n\n                          urls  verified hashtags      timestamp  TweetID  \n0                           []         0       []  1646978048000   832509  \n1                           []         0       []  1647694288000  1388011  \n2                           []         0       []  1647370048000    63896  \n3  ['https://t.co/rytlted08g']         0       []  1647256282000   979251  \n4                           []         0       []  1647258374000  1040049  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>mentions</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt refarcir macron ans nom prépare</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1646978048000</td>\n      <td>832509</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>populaire</td>\n      <td>0</td>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647694288000</td>\n      <td>1388011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>faut dégager cinglé</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647370048000</td>\n      <td>63896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enseignants mettre prescriptions président rép...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>['https://t.co/rytlted08g']</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647256282000</td>\n      <td>979251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mafieuse oppressive macron</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647258374000</td>\n      <td>1040049</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   favorites_count  followers_count  statuses_count  friends_count  urls  \\\n0                0             3682          453535           3628     0   \n1                0               86            1016            284     0   \n2                1             1944           28234           1995     0   \n3                0                1            1072              0     1   \n4                0            13957           25311          10841     0   \n\n   verified  hashtags  \n0         0         0  \n1         0         0  \n2         0         0  \n3         0         0  \n4         0         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_input = train_df.drop(['TweetID', 'timestamp', 'mentions', 'retweets_count', 'text'], axis=1)\n",
    "\n",
    "train_df_input.urls = train_df_input.urls.apply(ast.literal_eval)\n",
    "train_df_input.urls = train_df_input.urls.apply(len)\n",
    "\n",
    "train_df_input.hashtags = train_df_input.hashtags.apply(ast.literal_eval)\n",
    "train_df_input.hashtags = train_df_input.hashtags.apply(len)\n",
    "\n",
    "train_df_input.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_df_input = test_df.drop(['TweetID', 'timestamp', 'mentions', 'text'], axis=1)\n",
    "\n",
    "test_df_input.urls = test_df_input.urls.apply(ast.literal_eval)\n",
    "test_df_input.urls = test_df_input.urls.apply(len)\n",
    "\n",
    "test_df_input.hashtags = test_df_input.hashtags.apply(ast.literal_eval)\n",
    "test_df_input.hashtags = test_df_input.hashtags.apply(len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# k-fold Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def kfold_cv(X: pd.DataFrame,\n",
    "             y: pd.DataFrame,\n",
    "             n_splits: int = 10,\n",
    "             method: str = 'knn',\n",
    "             n_neighbors: int = 1):\n",
    "    kf = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=123456)\n",
    "    all_splits = [i for i in kf.split(X)]\n",
    "\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "\n",
    "    model = None\n",
    "    if method == 'knn':\n",
    "        model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "\n",
    "    for k in range(n_splits):\n",
    "        print('Training split', k)\n",
    "        train_indexes, val_indexes = all_splits[k]\n",
    "\n",
    "        train_X = X.iloc[train_indexes].values\n",
    "        mean = train_X.mean(0)\n",
    "        std = train_X.std(0)\n",
    "        train_X = (train_X - mean) / std\n",
    "        train_y = y.iloc[train_indexes].values\n",
    "\n",
    "        val_X = X.iloc[val_indexes].values\n",
    "        val_X = (val_X - mean) / std\n",
    "        val_y = y.iloc[val_indexes].values\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        train_predictions = model.predict(train_X)\n",
    "        val_predictions = model.predict(val_X)\n",
    "\n",
    "        train_mse.append(np.abs(train_predictions - train_y).mean())\n",
    "        val_mse.append(np.abs(val_predictions - val_y).mean())\n",
    "\n",
    "    return (sum(train_mse) / len(train_mse), sum(val_mse) / len(val_mse))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# for n in range(7, 17, 2):\n",
    "#     print(n, 'neighbors...')\n",
    "#     print(kfold_cv(train_df_input, train_df['retweets_count'], n_splits=5, n_neighbors=n))\n",
    "\n",
    "# Output of above loop\n",
    "knn_mse = { 1: (0.0022840985090, 8.82755207099830),\n",
    "            3: (5.2445855803790, 7.50757052066827),\n",
    "            5: (5.9034562077925, 7.29391667684989),\n",
    "            7: (6.2303256518832, 7.21462506305364),\n",
    "            9: (6.4206208103262, 7.22025110296241),\n",
    "            11: (6.5645450982183, 7.21998145087708),\n",
    "            13: (6.6775331234898, 7.24705572946240),\n",
    "            15: (6.7655345805517, 7.28415542343034)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submit simple models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "make_submission = False\n",
    "\n",
    "if make_submission:\n",
    "    mean = train_df_input.values.mean(0)\n",
    "    std = train_df_input.values.std(0)\n",
    "\n",
    "    train_X = (train_df_input.values - mean) /  std\n",
    "    test_X = (test_df_input.values - mean) / std\n",
    "\n",
    "    test_ids = test_df[['TweetID']]\n",
    "    model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "    model.fit(train_X, train_df['retweets_count'])\n",
    "    test_predictions = model.predict(test_X)\n",
    "\n",
    "    submission_df = pd.DataFrame(data={'retweets_count': test_predictions})\n",
    "    submission_df = pd.concat([test_ids, submission_df], axis=1)\n",
    "    submission_df.to_csv('data/submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 13:03:05,143 : INFO : collecting all words and their counts\n",
      "2022-11-14 13:03:05,172 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-14 13:03:05,204 : INFO : PROGRESS: at sentence #10000, processed 92512 words, keeping 18699 word types\n",
      "2022-11-14 13:03:05,255 : INFO : PROGRESS: at sentence #20000, processed 184983 words, keeping 27361 word types\n",
      "2022-11-14 13:03:05,303 : INFO : PROGRESS: at sentence #30000, processed 277832 words, keeping 33853 word types\n",
      "2022-11-14 13:03:05,342 : INFO : PROGRESS: at sentence #40000, processed 370444 words, keeping 39273 word types\n",
      "2022-11-14 13:03:05,384 : INFO : PROGRESS: at sentence #50000, processed 462540 words, keeping 43943 word types\n",
      "2022-11-14 13:03:05,429 : INFO : PROGRESS: at sentence #60000, processed 555094 words, keeping 47971 word types\n",
      "2022-11-14 13:03:05,488 : INFO : PROGRESS: at sentence #70000, processed 646885 words, keeping 51526 word types\n",
      "2022-11-14 13:03:05,535 : INFO : PROGRESS: at sentence #80000, processed 740165 words, keeping 55050 word types\n",
      "2022-11-14 13:03:05,589 : INFO : PROGRESS: at sentence #90000, processed 833010 words, keeping 58312 word types\n",
      "2022-11-14 13:03:05,641 : INFO : PROGRESS: at sentence #100000, processed 925776 words, keeping 61385 word types\n",
      "2022-11-14 13:03:05,695 : INFO : PROGRESS: at sentence #110000, processed 1017901 words, keeping 64109 word types\n",
      "2022-11-14 13:03:05,743 : INFO : PROGRESS: at sentence #120000, processed 1110686 words, keeping 66964 word types\n",
      "2022-11-14 13:03:05,791 : INFO : PROGRESS: at sentence #130000, processed 1203836 words, keeping 69643 word types\n",
      "2022-11-14 13:03:05,838 : INFO : PROGRESS: at sentence #140000, processed 1296301 words, keeping 72131 word types\n",
      "2022-11-14 13:03:05,887 : INFO : PROGRESS: at sentence #150000, processed 1387892 words, keeping 74363 word types\n",
      "2022-11-14 13:03:05,938 : INFO : PROGRESS: at sentence #160000, processed 1479938 words, keeping 76577 word types\n",
      "2022-11-14 13:03:05,983 : INFO : PROGRESS: at sentence #170000, processed 1573692 words, keeping 78870 word types\n",
      "2022-11-14 13:03:06,033 : INFO : PROGRESS: at sentence #180000, processed 1666272 words, keeping 80956 word types\n",
      "2022-11-14 13:03:06,093 : INFO : PROGRESS: at sentence #190000, processed 1759039 words, keeping 82971 word types\n",
      "2022-11-14 13:03:06,148 : INFO : PROGRESS: at sentence #200000, processed 1851197 words, keeping 84938 word types\n",
      "2022-11-14 13:03:06,207 : INFO : PROGRESS: at sentence #210000, processed 1943040 words, keeping 86918 word types\n",
      "2022-11-14 13:03:06,262 : INFO : PROGRESS: at sentence #220000, processed 2035371 words, keeping 88754 word types\n",
      "2022-11-14 13:03:06,317 : INFO : PROGRESS: at sentence #230000, processed 2128090 words, keeping 90559 word types\n",
      "2022-11-14 13:03:06,365 : INFO : PROGRESS: at sentence #240000, processed 2220527 words, keeping 92353 word types\n",
      "2022-11-14 13:03:06,422 : INFO : PROGRESS: at sentence #250000, processed 2313153 words, keeping 94023 word types\n",
      "2022-11-14 13:03:06,481 : INFO : PROGRESS: at sentence #260000, processed 2405451 words, keeping 95714 word types\n",
      "2022-11-14 13:03:06,538 : INFO : PROGRESS: at sentence #270000, processed 2498430 words, keeping 97335 word types\n",
      "2022-11-14 13:03:06,595 : INFO : PROGRESS: at sentence #280000, processed 2590195 words, keeping 98822 word types\n",
      "2022-11-14 13:03:06,652 : INFO : PROGRESS: at sentence #290000, processed 2681934 words, keeping 100404 word types\n",
      "2022-11-14 13:03:06,712 : INFO : PROGRESS: at sentence #300000, processed 2774645 words, keeping 102065 word types\n",
      "2022-11-14 13:03:06,767 : INFO : PROGRESS: at sentence #310000, processed 2867600 words, keeping 103538 word types\n",
      "2022-11-14 13:03:06,822 : INFO : PROGRESS: at sentence #320000, processed 2960934 words, keeping 105039 word types\n",
      "2022-11-14 13:03:06,879 : INFO : PROGRESS: at sentence #330000, processed 3052412 words, keeping 106549 word types\n",
      "2022-11-14 13:03:06,935 : INFO : PROGRESS: at sentence #340000, processed 3145245 words, keeping 108025 word types\n",
      "2022-11-14 13:03:06,992 : INFO : PROGRESS: at sentence #350000, processed 3238509 words, keeping 109481 word types\n",
      "2022-11-14 13:03:07,033 : INFO : collected 110060 word types from a corpus of 3275127 raw words and 353969 sentences\n",
      "2022-11-14 13:03:07,034 : INFO : Creating a fresh vocabulary\n",
      "2022-11-14 13:03:07,567 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 110060 unique words (100.00% of original 110060, drops 0)', 'datetime': '2022-11-14T13:03:07.567066', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 13:03:07,568 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3275127 word corpus (100.00% of original 3275127, drops 0)', 'datetime': '2022-11-14T13:03:07.568067', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 13:03:08,431 : INFO : deleting the raw counts dictionary of 110060 items\n",
      "2022-11-14 13:03:08,434 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2022-11-14 13:03:08,435 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3027731.485837764 word corpus (92.4%% of prior 3275127)', 'datetime': '2022-11-14T13:03:08.435265', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 13:03:09,638 : INFO : estimated required memory for 110060 words and 256 dimensions: 280432880 bytes\n",
      "2022-11-14 13:03:09,639 : INFO : resetting layer weights\n",
      "2022-11-14 13:03:09,780 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-14T13:03:09.780815', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2022-11-14 13:03:09,781 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 110060 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-11-14T13:03:09.781828', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-14 13:03:10,834 : INFO : EPOCH 0 - PROGRESS: at 15.56% examples, 461973 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:11,838 : INFO : EPOCH 0 - PROGRESS: at 33.87% examples, 506994 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:12,840 : INFO : EPOCH 0 - PROGRESS: at 50.95% examples, 510094 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-14 13:03:13,844 : INFO : EPOCH 0 - PROGRESS: at 69.27% examples, 520554 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:14,864 : INFO : EPOCH 0 - PROGRESS: at 87.00% examples, 521618 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:15,572 : INFO : EPOCH 0: training on 3275127 raw words (3027909 effective words) took 5.8s, 526014 effective words/s\n",
      "2022-11-14 13:03:16,592 : INFO : EPOCH 1 - PROGRESS: at 15.25% examples, 461175 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:17,631 : INFO : EPOCH 1 - PROGRESS: at 30.21% examples, 448153 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:18,640 : INFO : EPOCH 1 - PROGRESS: at 47.29% examples, 469443 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:19,649 : INFO : EPOCH 1 - PROGRESS: at 62.26% examples, 464386 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:20,671 : INFO : EPOCH 1 - PROGRESS: at 77.52% examples, 461940 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:21,688 : INFO : EPOCH 1 - PROGRESS: at 95.24% examples, 472795 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:21,902 : INFO : EPOCH 1: training on 3275127 raw words (3028268 effective words) took 6.3s, 479808 effective words/s\n",
      "2022-11-14 13:03:22,920 : INFO : EPOCH 2 - PROGRESS: at 13.42% examples, 405250 words/s, in_qsize 7, out_qsize 1\n",
      "2022-11-14 13:03:23,953 : INFO : EPOCH 2 - PROGRESS: at 30.21% examples, 448927 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:24,972 : INFO : EPOCH 2 - PROGRESS: at 41.79% examples, 414202 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:25,973 : INFO : EPOCH 2 - PROGRESS: at 60.11% examples, 448712 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:26,975 : INFO : EPOCH 2 - PROGRESS: at 76.29% examples, 456620 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:27,978 : INFO : EPOCH 2 - PROGRESS: at 94.94% examples, 474062 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-14 13:03:28,231 : INFO : EPOCH 2: training on 3275127 raw words (3027742 effective words) took 6.3s, 479551 effective words/s\n",
      "2022-11-14 13:03:29,253 : INFO : EPOCH 3 - PROGRESS: at 12.51% examples, 376569 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:30,256 : INFO : EPOCH 3 - PROGRESS: at 29.59% examples, 446167 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-14 13:03:31,270 : INFO : EPOCH 3 - PROGRESS: at 46.08% examples, 461490 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-14 13:03:32,277 : INFO : EPOCH 3 - PROGRESS: at 60.42% examples, 453883 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:33,282 : INFO : EPOCH 3 - PROGRESS: at 78.14% examples, 469748 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:34,299 : INFO : EPOCH 3 - PROGRESS: at 94.34% examples, 471760 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:34,553 : INFO : EPOCH 3: training on 3275127 raw words (3027454 effective words) took 6.3s, 480127 effective words/s\n",
      "2022-11-14 13:03:35,574 : INFO : EPOCH 4 - PROGRESS: at 17.09% examples, 514662 words/s, in_qsize 7, out_qsize 1\n",
      "2022-11-14 13:03:36,583 : INFO : EPOCH 4 - PROGRESS: at 32.35% examples, 486043 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 13:03:37,587 : INFO : EPOCH 4 - PROGRESS: at 50.03% examples, 501992 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:38,606 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 469144 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:39,616 : INFO : EPOCH 4 - PROGRESS: at 77.52% examples, 464959 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:40,618 : INFO : EPOCH 4 - PROGRESS: at 93.41% examples, 467402 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 13:03:40,962 : INFO : EPOCH 4: training on 3275127 raw words (3028276 effective words) took 6.4s, 473648 effective words/s\n",
      "2022-11-14 13:03:40,963 : INFO : Word2Vec lifecycle event {'msg': 'training on 16375635 raw words (15139649 effective words) took 31.2s, 485549 effective words/s', 'datetime': '2022-11-14T13:03:40.963211', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-14 13:03:40,964 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=110060, vector_size=256, alpha=0.025>', 'datetime': '2022-11-14T13:03:40.964209', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-11-14 13:03:41,018 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'models/word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-14T13:03:41.018429', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'saving'}\n",
      "2022-11-14 13:03:41,020 : INFO : storing np array 'vectors' to models/word2vec.model.wv.vectors.npy\n",
      "2022-11-14 13:03:41,223 : INFO : storing np array 'syn1neg' to models/word2vec.model.syn1neg.npy\n",
      "2022-11-14 13:03:41,409 : INFO : not storing attribute cum_table\n",
      "2022-11-14 13:03:41,476 : INFO : saved models/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, text_df: pd.DataFrame):\n",
    "        self.df = text_df\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tweet in self.df['text'].to_list():\n",
    "            yield tweet.split(' ')\n",
    "\n",
    "tweets = Corpus(train_df)\n",
    "model = gensim.models.Word2Vec(tweets, min_count=1, vector_size=256, workers=4)\n",
    "model.save('models/word2vec.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
