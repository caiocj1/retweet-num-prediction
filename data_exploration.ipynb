{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import gensim, logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       retweets_count  favorites_count  followers_count  statuses_count  \\\ncount   353969.000000    353969.000000     3.539690e+05    3.539690e+05   \nmean        15.831810        46.655442     2.021548e+04    4.808507e+04   \nstd        241.986723       852.044385     2.598715e+05    1.133854e+05   \nmin          0.000000         0.000000     0.000000e+00    1.000000e+00   \n25%          0.000000         0.000000     1.600000e+02    2.972000e+03   \n50%          1.000000         0.000000     7.260000e+02    1.250100e+04   \n75%          3.000000         1.000000     2.283000e+03    4.352200e+04   \nmax      63674.000000    122591.000000     1.441710e+07    8.183508e+06   \n\n       friends_count       verified     timestamp       TweetID  \ncount  353969.000000  353969.000000  3.539690e+05  3.539690e+05  \nmean     1459.289003       0.030005  1.647004e+12  6.872503e+05  \nstd      2502.933271       0.170602  4.846468e+09  4.175793e+05  \nmin         0.000000       0.000000  1.301178e+12  3.000000e+00  \n25%       214.000000       0.000000  1.647068e+12  3.194490e+05  \n50%       693.000000       0.000000  1.647292e+12  6.719730e+05  \n75%      1804.000000       0.000000  1.647532e+12  1.049644e+06  \nmax    237269.000000       1.000000  1.647727e+12  1.434456e+06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>verified</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>15.831810</td>\n      <td>46.655442</td>\n      <td>2.021548e+04</td>\n      <td>4.808507e+04</td>\n      <td>1459.289003</td>\n      <td>0.030005</td>\n      <td>1.647004e+12</td>\n      <td>6.872503e+05</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>241.986723</td>\n      <td>852.044385</td>\n      <td>2.598715e+05</td>\n      <td>1.133854e+05</td>\n      <td>2502.933271</td>\n      <td>0.170602</td>\n      <td>4.846468e+09</td>\n      <td>4.175793e+05</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.301178e+12</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.600000e+02</td>\n      <td>2.972000e+03</td>\n      <td>214.000000</td>\n      <td>0.000000</td>\n      <td>1.647068e+12</td>\n      <td>3.194490e+05</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.260000e+02</td>\n      <td>1.250100e+04</td>\n      <td>693.000000</td>\n      <td>0.000000</td>\n      <td>1.647292e+12</td>\n      <td>6.719730e+05</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.283000e+03</td>\n      <td>4.352200e+04</td>\n      <td>1804.000000</td>\n      <td>0.000000</td>\n      <td>1.647532e+12</td>\n      <td>1.049644e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>63674.000000</td>\n      <td>122591.000000</td>\n      <td>1.441710e+07</td>\n      <td>8.183508e+06</td>\n      <td>237269.000000</td>\n      <td>1.000000</td>\n      <td>1.647727e+12</td>\n      <td>1.434456e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/evaluation.csv')\n",
    "train_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  retweets_count  \\\n0                 rt refarcir macron ans nom prépare               3   \n1                                          populaire               0   \n2                                faut dégager cinglé               3   \n3  enseignants mettre prescriptions président rép...               0   \n4                         mafieuse oppressive macron               0   \n\n   favorites_count  followers_count  statuses_count  friends_count mentions  \\\n0                0             3682          453535           3628       []   \n1                0               86            1016            284       []   \n2                1             1944           28234           1995       []   \n3                0                1            1072              0       []   \n4                0            13957           25311          10841       []   \n\n                          urls  verified hashtags      timestamp  TweetID  \n0                           []         0       []  1646978048000   832509  \n1                           []         0       []  1647694288000  1388011  \n2                           []         0       []  1647370048000    63896  \n3  ['https://t.co/rytlted08g']         0       []  1647256282000   979251  \n4                           []         0       []  1647258374000  1040049  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>mentions</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt refarcir macron ans nom prépare</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1646978048000</td>\n      <td>832509</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>populaire</td>\n      <td>0</td>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647694288000</td>\n      <td>1388011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>faut dégager cinglé</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647370048000</td>\n      <td>63896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enseignants mettre prescriptions président rép...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>['https://t.co/rytlted08g']</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647256282000</td>\n      <td>979251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mafieuse oppressive macron</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647258374000</td>\n      <td>1040049</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   favorites_count  followers_count  statuses_count  friends_count  urls  \\\n0                0             3682          453535           3628     0   \n1                0               86            1016            284     0   \n2                1             1944           28234           1995     0   \n3                0                1            1072              0     1   \n4                0            13957           25311          10841     0   \n\n   verified  hashtags  \n0         0         0  \n1         0         0  \n2         0         0  \n3         0         0  \n4         0         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_input = train_df.drop(['TweetID', 'timestamp', 'mentions', 'retweets_count', 'text'], axis=1)\n",
    "\n",
    "train_df_input.urls = train_df_input.urls.apply(ast.literal_eval)\n",
    "train_df_input.urls = train_df_input.urls.apply(len)\n",
    "\n",
    "train_df_input.hashtags = train_df_input.hashtags.apply(ast.literal_eval)\n",
    "train_df_input.hashtags = train_df_input.hashtags.apply(len)\n",
    "\n",
    "train_df_input.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_df_input = test_df.drop(['TweetID', 'timestamp', 'mentions', 'text'], axis=1)\n",
    "\n",
    "test_df_input.urls = test_df_input.urls.apply(ast.literal_eval)\n",
    "test_df_input.urls = test_df_input.urls.apply(len)\n",
    "\n",
    "test_df_input.hashtags = test_df_input.hashtags.apply(ast.literal_eval)\n",
    "test_df_input.hashtags = test_df_input.hashtags.apply(len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# k-fold Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def kfold_cv(X: pd.DataFrame,\n",
    "             y: pd.DataFrame,\n",
    "             n_splits: int = 10,\n",
    "             method: str = 'knn',\n",
    "             n_neighbors: int = 1):\n",
    "    kf = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=123456)\n",
    "    all_splits = [i for i in kf.split(X)]\n",
    "\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "\n",
    "    model = None\n",
    "    if method == 'knn':\n",
    "        model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "\n",
    "    for k in range(n_splits):\n",
    "        print('Training split', k)\n",
    "        train_indexes, val_indexes = all_splits[k]\n",
    "\n",
    "        train_X = X.iloc[train_indexes].values\n",
    "        mean = train_X.mean(0)\n",
    "        std = train_X.std(0)\n",
    "        train_X = (train_X - mean) / std\n",
    "        train_y = y.iloc[train_indexes].values\n",
    "\n",
    "        val_X = X.iloc[val_indexes].values\n",
    "        val_X = (val_X - mean) / std\n",
    "        val_y = y.iloc[val_indexes].values\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "        train_predictions = model.predict(train_X)\n",
    "        val_predictions = model.predict(val_X)\n",
    "\n",
    "        train_mse.append(np.abs(train_predictions - train_y).mean())\n",
    "        val_mse.append(np.abs(val_predictions - val_y).mean())\n",
    "\n",
    "    return (sum(train_mse) / len(train_mse), sum(val_mse) / len(val_mse))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# for n in range(7, 17, 2):\n",
    "#     print(n, 'neighbors...')\n",
    "#     print(kfold_cv(train_df_input, train_df['retweets_count'], n_splits=5, n_neighbors=n))\n",
    "\n",
    "# Output of above loop\n",
    "knn_mse = { 1: (0.0022840985090, 8.82755207099830),\n",
    "            3: (5.2445855803790, 7.50757052066827),\n",
    "            5: (5.9034562077925, 7.29391667684989),\n",
    "            7: (6.2303256518832, 7.21462506305364),\n",
    "            9: (6.4206208103262, 7.22025110296241),\n",
    "            11: (6.5645450982183, 7.21998145087708),\n",
    "            13: (6.6775331234898, 7.24705572946240),\n",
    "            15: (6.7655345805517, 7.28415542343034)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submit simple models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "make_submission = False\n",
    "\n",
    "if make_submission:\n",
    "    mean = train_df_input.values.mean(0)\n",
    "    std = train_df_input.values.std(0)\n",
    "\n",
    "    train_X = (train_df_input.values - mean) /  std\n",
    "    test_X = (test_df_input.values - mean) / std\n",
    "\n",
    "    test_ids = test_df[['TweetID']]\n",
    "    model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "    model.fit(train_X, train_df['retweets_count'])\n",
    "    test_predictions = model.predict(test_X)\n",
    "\n",
    "    submission_df = pd.DataFrame(data={'retweets_count': test_predictions})\n",
    "    submission_df = pd.concat([test_ids, submission_df], axis=1)\n",
    "    submission_df.to_csv('data/submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 09:15:24,637 : INFO : collecting all words and their counts\n",
      "2022-11-14 09:15:24,722 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-14 09:15:24,761 : INFO : PROGRESS: at sentence #10000, processed 92512 words, keeping 18699 word types\n",
      "2022-11-14 09:15:24,805 : INFO : PROGRESS: at sentence #20000, processed 184983 words, keeping 27361 word types\n",
      "2022-11-14 09:15:24,852 : INFO : PROGRESS: at sentence #30000, processed 277832 words, keeping 33853 word types\n",
      "2022-11-14 09:15:24,900 : INFO : PROGRESS: at sentence #40000, processed 370444 words, keeping 39273 word types\n",
      "2022-11-14 09:15:24,949 : INFO : PROGRESS: at sentence #50000, processed 462540 words, keeping 43943 word types\n",
      "2022-11-14 09:15:24,991 : INFO : PROGRESS: at sentence #60000, processed 555094 words, keeping 47971 word types\n",
      "2022-11-14 09:15:25,032 : INFO : PROGRESS: at sentence #70000, processed 646885 words, keeping 51526 word types\n",
      "2022-11-14 09:15:25,072 : INFO : PROGRESS: at sentence #80000, processed 740165 words, keeping 55050 word types\n",
      "2022-11-14 09:15:25,114 : INFO : PROGRESS: at sentence #90000, processed 833010 words, keeping 58312 word types\n",
      "2022-11-14 09:15:25,155 : INFO : PROGRESS: at sentence #100000, processed 925776 words, keeping 61385 word types\n",
      "2022-11-14 09:15:25,198 : INFO : PROGRESS: at sentence #110000, processed 1017901 words, keeping 64109 word types\n",
      "2022-11-14 09:15:25,242 : INFO : PROGRESS: at sentence #120000, processed 1110686 words, keeping 66964 word types\n",
      "2022-11-14 09:15:25,287 : INFO : PROGRESS: at sentence #130000, processed 1203836 words, keeping 69643 word types\n",
      "2022-11-14 09:15:25,326 : INFO : PROGRESS: at sentence #140000, processed 1296301 words, keeping 72131 word types\n",
      "2022-11-14 09:15:25,363 : INFO : PROGRESS: at sentence #150000, processed 1387892 words, keeping 74363 word types\n",
      "2022-11-14 09:15:25,405 : INFO : PROGRESS: at sentence #160000, processed 1479938 words, keeping 76577 word types\n",
      "2022-11-14 09:15:25,445 : INFO : PROGRESS: at sentence #170000, processed 1573692 words, keeping 78870 word types\n",
      "2022-11-14 09:15:25,479 : INFO : PROGRESS: at sentence #180000, processed 1666272 words, keeping 80956 word types\n",
      "2022-11-14 09:15:25,521 : INFO : PROGRESS: at sentence #190000, processed 1759039 words, keeping 82971 word types\n",
      "2022-11-14 09:15:25,560 : INFO : PROGRESS: at sentence #200000, processed 1851197 words, keeping 84938 word types\n",
      "2022-11-14 09:15:25,598 : INFO : PROGRESS: at sentence #210000, processed 1943040 words, keeping 86918 word types\n",
      "2022-11-14 09:15:25,641 : INFO : PROGRESS: at sentence #220000, processed 2035371 words, keeping 88754 word types\n",
      "2022-11-14 09:15:25,680 : INFO : PROGRESS: at sentence #230000, processed 2128090 words, keeping 90559 word types\n",
      "2022-11-14 09:15:25,719 : INFO : PROGRESS: at sentence #240000, processed 2220527 words, keeping 92353 word types\n",
      "2022-11-14 09:15:25,758 : INFO : PROGRESS: at sentence #250000, processed 2313153 words, keeping 94023 word types\n",
      "2022-11-14 09:15:25,795 : INFO : PROGRESS: at sentence #260000, processed 2405451 words, keeping 95714 word types\n",
      "2022-11-14 09:15:25,832 : INFO : PROGRESS: at sentence #270000, processed 2498430 words, keeping 97335 word types\n",
      "2022-11-14 09:15:25,869 : INFO : PROGRESS: at sentence #280000, processed 2590195 words, keeping 98822 word types\n",
      "2022-11-14 09:15:25,907 : INFO : PROGRESS: at sentence #290000, processed 2681934 words, keeping 100404 word types\n",
      "2022-11-14 09:15:25,947 : INFO : PROGRESS: at sentence #300000, processed 2774645 words, keeping 102065 word types\n",
      "2022-11-14 09:15:25,985 : INFO : PROGRESS: at sentence #310000, processed 2867600 words, keeping 103538 word types\n",
      "2022-11-14 09:15:26,024 : INFO : PROGRESS: at sentence #320000, processed 2960934 words, keeping 105039 word types\n",
      "2022-11-14 09:15:26,064 : INFO : PROGRESS: at sentence #330000, processed 3052412 words, keeping 106549 word types\n",
      "2022-11-14 09:15:26,107 : INFO : PROGRESS: at sentence #340000, processed 3145245 words, keeping 108025 word types\n",
      "2022-11-14 09:15:26,151 : INFO : PROGRESS: at sentence #350000, processed 3238509 words, keeping 109481 word types\n",
      "2022-11-14 09:15:26,178 : INFO : collected 110060 word types from a corpus of 3275127 raw words and 353969 sentences\n",
      "2022-11-14 09:15:26,180 : INFO : Creating a fresh vocabulary\n",
      "2022-11-14 09:15:26,609 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 110060 unique words (100.00% of original 110060, drops 0)', 'datetime': '2022-11-14T09:15:26.609066', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 09:15:26,609 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3275127 word corpus (100.00% of original 3275127, drops 0)', 'datetime': '2022-11-14T09:15:26.609648', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 09:15:27,301 : INFO : deleting the raw counts dictionary of 110060 items\n",
      "2022-11-14 09:15:27,305 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2022-11-14 09:15:27,306 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3027731.485837764 word corpus (92.4%% of prior 3275127)', 'datetime': '2022-11-14T09:15:27.306872', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-14 09:15:28,350 : INFO : estimated required memory for 110060 words and 200 dimensions: 231126000 bytes\n",
      "2022-11-14 09:15:28,352 : INFO : resetting layer weights\n",
      "2022-11-14 09:15:28,478 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-14T09:15:28.478646', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2022-11-14 09:15:28,480 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 110060 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-11-14T09:15:28.480648', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-14 09:15:29,552 : INFO : EPOCH 0 - PROGRESS: at 9.76% examples, 288090 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:30,561 : INFO : EPOCH 0 - PROGRESS: at 26.24% examples, 390259 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:31,604 : INFO : EPOCH 0 - PROGRESS: at 42.72% examples, 420121 words/s, in_qsize 7, out_qsize 2\n",
      "2022-11-14 09:15:32,644 : INFO : EPOCH 0 - PROGRESS: at 59.21% examples, 435217 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:33,648 : INFO : EPOCH 0 - PROGRESS: at 78.14% examples, 461816 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 09:15:34,655 : INFO : EPOCH 0 - PROGRESS: at 95.85% examples, 473407 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-14 09:15:34,820 : INFO : EPOCH 0: training on 3275127 raw words (3027788 effective words) took 6.3s, 481025 effective words/s\n",
      "2022-11-14 09:15:35,885 : INFO : EPOCH 1 - PROGRESS: at 16.18% examples, 467295 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:36,905 : INFO : EPOCH 1 - PROGRESS: at 35.99% examples, 527108 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:37,911 : INFO : EPOCH 1 - PROGRESS: at 52.77% examples, 519899 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-14 09:15:38,931 : INFO : EPOCH 1 - PROGRESS: at 71.71% examples, 530240 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 09:15:40,037 : INFO : EPOCH 1 - PROGRESS: at 88.22% examples, 513514 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-14 09:15:40,669 : INFO : EPOCH 1: training on 3275127 raw words (3027422 effective words) took 5.8s, 519221 effective words/s\n",
      "2022-11-14 09:15:41,692 : INFO : EPOCH 2 - PROGRESS: at 14.65% examples, 441650 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:42,706 : INFO : EPOCH 2 - PROGRESS: at 28.67% examples, 430365 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:43,737 : INFO : EPOCH 2 - PROGRESS: at 43.03% examples, 427140 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:44,742 : INFO : EPOCH 2 - PROGRESS: at 51.25% examples, 382804 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:45,763 : INFO : EPOCH 2 - PROGRESS: at 64.09% examples, 382198 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 09:15:46,784 : INFO : EPOCH 2 - PROGRESS: at 77.83% examples, 386442 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 09:15:47,807 : INFO : EPOCH 2 - PROGRESS: at 95.85% examples, 407510 words/s, in_qsize 8, out_qsize 3\n",
      "2022-11-14 09:15:47,962 : INFO : EPOCH 2: training on 3275127 raw words (3027263 effective words) took 7.3s, 416138 effective words/s\n",
      "2022-11-14 09:15:48,998 : INFO : EPOCH 3 - PROGRESS: at 13.73% examples, 414400 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:50,028 : INFO : EPOCH 3 - PROGRESS: at 30.52% examples, 454198 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:51,052 : INFO : EPOCH 3 - PROGRESS: at 41.18% examples, 407927 words/s, in_qsize 7, out_qsize 1\n",
      "2022-11-14 09:15:52,055 : INFO : EPOCH 3 - PROGRESS: at 57.04% examples, 425416 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:53,107 : INFO : EPOCH 3 - PROGRESS: at 69.58% examples, 412059 words/s, in_qsize 7, out_qsize 1\n",
      "2022-11-14 09:15:54,108 : INFO : EPOCH 3 - PROGRESS: at 86.70% examples, 429208 words/s, in_qsize 7, out_qsize 1\n",
      "2022-11-14 09:15:54,874 : INFO : EPOCH 3: training on 3275127 raw words (3027587 effective words) took 6.9s, 440119 effective words/s\n",
      "2022-11-14 09:15:55,910 : INFO : EPOCH 4 - PROGRESS: at 13.12% examples, 394807 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-14 09:15:56,924 : INFO : EPOCH 4 - PROGRESS: at 30.82% examples, 462082 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:57,964 : INFO : EPOCH 4 - PROGRESS: at 46.69% examples, 462175 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:15:58,964 : INFO : EPOCH 4 - PROGRESS: at 62.87% examples, 468879 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-14 09:16:00,064 : INFO : EPOCH 4 - PROGRESS: at 74.77% examples, 438748 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-14 09:16:01,083 : INFO : EPOCH 4 - PROGRESS: at 87.91% examples, 430663 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-14 09:16:01,889 : INFO : EPOCH 4: training on 3275127 raw words (3027975 effective words) took 7.0s, 433445 effective words/s\n",
      "2022-11-14 09:16:01,890 : INFO : Word2Vec lifecycle event {'msg': 'training on 16375635 raw words (15138035 effective words) took 33.4s, 453104 effective words/s', 'datetime': '2022-11-14T09:16:01.890904', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-14 09:16:01,892 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=110060, vector_size=200, alpha=0.025>', 'datetime': '2022-11-14T09:16:01.891906', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-11-14 09:16:01,894 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'models/word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-14T09:16:01.894925', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'saving'}\n",
      "2022-11-14 09:16:01,896 : INFO : storing np array 'vectors' to models/word2vec.model.wv.vectors.npy\n",
      "2022-11-14 09:16:02,046 : INFO : storing np array 'syn1neg' to models/word2vec.model.syn1neg.npy\n",
      "2022-11-14 09:16:02,203 : INFO : not storing attribute cum_table\n",
      "2022-11-14 09:16:02,293 : INFO : saved models/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, text_df: pd.DataFrame):\n",
    "        self.df = text_df\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tweet in self.df['text'].to_list():\n",
    "            yield tweet.split(' ')\n",
    "\n",
    "tweets = Corpus(train_df)\n",
    "model = gensim.models.Word2Vec(tweets, min_count=1, vector_size=200, workers=4)\n",
    "model.save('models/word2vec.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
