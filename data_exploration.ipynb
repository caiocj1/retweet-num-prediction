{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caioj\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "import sklearn.ensemble\n",
    "import sklearn.cluster\n",
    "import sklearn.feature_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import gensim, logging\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import datetime\n",
    "import seaborn as sbn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       retweets_count  favorites_count  followers_count  statuses_count  \\\ncount   353969.000000    353969.000000     3.539690e+05    3.539690e+05   \nmean        15.831810        46.655442     2.021548e+04    4.808507e+04   \nstd        241.986723       852.044385     2.598715e+05    1.133854e+05   \nmin          0.000000         0.000000     0.000000e+00    1.000000e+00   \n25%          0.000000         0.000000     1.600000e+02    2.972000e+03   \n50%          1.000000         0.000000     7.260000e+02    1.250100e+04   \n75%          3.000000         1.000000     2.283000e+03    4.352200e+04   \nmax      63674.000000    122591.000000     1.441710e+07    8.183508e+06   \n\n       friends_count       verified     timestamp       TweetID  \ncount  353969.000000  353969.000000  3.539690e+05  3.539690e+05  \nmean     1459.289003       0.030005  1.647004e+12  6.872503e+05  \nstd      2502.933271       0.170602  4.846468e+09  4.175793e+05  \nmin         0.000000       0.000000  1.301178e+12  3.000000e+00  \n25%       214.000000       0.000000  1.647068e+12  3.194490e+05  \n50%       693.000000       0.000000  1.647292e+12  6.719730e+05  \n75%      1804.000000       0.000000  1.647532e+12  1.049644e+06  \nmax    237269.000000       1.000000  1.647727e+12  1.434456e+06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>verified</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n      <td>353969.000000</td>\n      <td>353969.000000</td>\n      <td>3.539690e+05</td>\n      <td>3.539690e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>15.831810</td>\n      <td>46.655442</td>\n      <td>2.021548e+04</td>\n      <td>4.808507e+04</td>\n      <td>1459.289003</td>\n      <td>0.030005</td>\n      <td>1.647004e+12</td>\n      <td>6.872503e+05</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>241.986723</td>\n      <td>852.044385</td>\n      <td>2.598715e+05</td>\n      <td>1.133854e+05</td>\n      <td>2502.933271</td>\n      <td>0.170602</td>\n      <td>4.846468e+09</td>\n      <td>4.175793e+05</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.301178e+12</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.600000e+02</td>\n      <td>2.972000e+03</td>\n      <td>214.000000</td>\n      <td>0.000000</td>\n      <td>1.647068e+12</td>\n      <td>3.194490e+05</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.260000e+02</td>\n      <td>1.250100e+04</td>\n      <td>693.000000</td>\n      <td>0.000000</td>\n      <td>1.647292e+12</td>\n      <td>6.719730e+05</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.283000e+03</td>\n      <td>4.352200e+04</td>\n      <td>1804.000000</td>\n      <td>0.000000</td>\n      <td>1.647532e+12</td>\n      <td>1.049644e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>63674.000000</td>\n      <td>122591.000000</td>\n      <td>1.441710e+07</td>\n      <td>8.183508e+06</td>\n      <td>237269.000000</td>\n      <td>1.000000</td>\n      <td>1.647727e+12</td>\n      <td>1.434456e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_train_df = pd.read_csv('data/train.csv')\n",
    "read_test_df = pd.read_csv('data/evaluation.csv')\n",
    "read_train_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     text  retweets_count  \\\n0                      rt refarcir macron ans nom prépare               3   \n1                                               populaire               0   \n2                                     faut dégager cinglé               3   \n3       enseignants mettre prescriptions président rép...               0   \n4                              mafieuse oppressive macron               0   \n...                                                   ...             ...   \n353964                     gonflette tour raciste frustré               0   \n353965  france caste crapuleuse encadrée gangsters irr...               0   \n353966                      eric zemmour français berbère               3   \n353967                           gauchistes dépression pq               0   \n353968      algérie emmanuel macron grande histoire amour               0   \n\n        favorites_count  followers_count  statuses_count  friends_count  \\\n0                     0             3682          453535           3628   \n1                     0               86            1016            284   \n2                     1             1944           28234           1995   \n3                     0                1            1072              0   \n4                     0            13957           25311          10841   \n...                 ...              ...             ...            ...   \n353964                0               34            1509             55   \n353965                0               89           11166            127   \n353966                0             1888             712           3086   \n353967                0              139             486            320   \n353968                0                0              82             24   \n\n       mentions                         urls  verified hashtags  \\\n0            []                           []         0       []   \n1            []                           []         0       []   \n2            []                           []         0       []   \n3            []  ['https://t.co/rytlted08g']         0       []   \n4            []                           []         0       []   \n...         ...                          ...       ...      ...   \n353964       []  ['https://t.co/pma33zhslx']         0       []   \n353965       []                           []         0       []   \n353966       []                           []         0       []   \n353967       []                           []         0       []   \n353968       []                           []         0       []   \n\n            timestamp  TweetID  \n0       1646978048000   832509  \n1       1647694288000  1388011  \n2       1647370048000    63896  \n3       1647256282000   979251  \n4       1647258374000  1040049  \n...               ...      ...  \n353964  1647438153000   142573  \n353965  1647072106000   240866  \n353966  1647607230000  1173763  \n353967  1646987195000   929182  \n353968  1647602843000  1250518  \n\n[353969 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>mentions</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n      <th>timestamp</th>\n      <th>TweetID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt refarcir macron ans nom prépare</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1646978048000</td>\n      <td>832509</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>populaire</td>\n      <td>0</td>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647694288000</td>\n      <td>1388011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>faut dégager cinglé</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647370048000</td>\n      <td>63896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enseignants mettre prescriptions président rép...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>['https://t.co/rytlted08g']</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647256282000</td>\n      <td>979251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mafieuse oppressive macron</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647258374000</td>\n      <td>1040049</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>353964</th>\n      <td>gonflette tour raciste frustré</td>\n      <td>0</td>\n      <td>0</td>\n      <td>34</td>\n      <td>1509</td>\n      <td>55</td>\n      <td>[]</td>\n      <td>['https://t.co/pma33zhslx']</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647438153000</td>\n      <td>142573</td>\n    </tr>\n    <tr>\n      <th>353965</th>\n      <td>france caste crapuleuse encadrée gangsters irr...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>89</td>\n      <td>11166</td>\n      <td>127</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647072106000</td>\n      <td>240866</td>\n    </tr>\n    <tr>\n      <th>353966</th>\n      <td>eric zemmour français berbère</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1888</td>\n      <td>712</td>\n      <td>3086</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647607230000</td>\n      <td>1173763</td>\n    </tr>\n    <tr>\n      <th>353967</th>\n      <td>gauchistes dépression pq</td>\n      <td>0</td>\n      <td>0</td>\n      <td>139</td>\n      <td>486</td>\n      <td>320</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1646987195000</td>\n      <td>929182</td>\n    </tr>\n    <tr>\n      <th>353968</th>\n      <td>algérie emmanuel macron grande histoire amour</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>82</td>\n      <td>24</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1647602843000</td>\n      <td>1250518</td>\n    </tr>\n  </tbody>\n</table>\n<p>353969 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "count    353969.0\nmean          0.0\nstd           0.0\nmin           0.0\n25%           0.0\n50%           0.0\n75%           0.0\nmax           0.0\nName: mentions, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_train_df['mentions'].apply(ast.literal_eval).apply(len).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "read_train_df.urls = read_train_df.urls.apply(ast.literal_eval)\n",
    "read_train_df.hashtags = read_train_df.hashtags.apply(ast.literal_eval)\n",
    "\n",
    "read_test_df.urls = read_test_df.urls.apply(ast.literal_eval)\n",
    "read_test_df.hashtags = read_test_df.hashtags.apply(ast.literal_eval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def format_df(df: pd.DataFrame,\n",
    "                  type: str = 'train',\n",
    "                  keep_time: bool = False):\n",
    "    final_df = df.drop(['TweetID', 'mentions', 'timestamp'], axis=1)\n",
    "\n",
    "    final_df['text'] = final_df['text'].apply(str.split)\n",
    "\n",
    "    final_df['url_count'] = final_df.urls.apply(len)\n",
    "    final_df['hashtag_count'] = final_df.hashtags.apply(len)\n",
    "\n",
    "    if keep_time:\n",
    "        timestamps = df.timestamp // 1000\n",
    "        timestamps = timestamps.apply(datetime.datetime.fromtimestamp).apply(datetime.datetime.timetuple)\n",
    "\n",
    "        time_df = pd.DataFrame(timestamps.tolist(), index=df.index,\n",
    "                               columns=['tm_year', 'tm_mon', 'tm_mday', 'tm_hour', 'tm_min', 'tm_sec', 'tm_wday',\n",
    "                                        'tm_yday', 'tm_isdst'])\n",
    "\n",
    "        final_df = pd.concat([final_df, time_df], axis=1)\n",
    "\n",
    "    return final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_df = format_df(read_train_df, keep_time=True)\n",
    "test_df = format_df(read_test_df, keep_time=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     text  retweets_count  \\\n0               [rt, refarcir, macron, ans, nom, prépare]               3   \n1                                             [populaire]               0   \n2                                 [faut, dégager, cinglé]               3   \n3       [enseignants, mettre, prescriptions, président...               0   \n4                          [mafieuse, oppressive, macron]               0   \n...                                                   ...             ...   \n353964                [gonflette, tour, raciste, frustré]               0   \n353965  [france, caste, crapuleuse, encadrée, gangster...               0   \n353966                 [eric, zemmour, français, berbère]               3   \n353967                       [gauchistes, dépression, pq]               0   \n353968  [algérie, emmanuel, macron, grande, histoire, ...               0   \n\n        favorites_count  followers_count  statuses_count  friends_count  \\\n0                     0             3682          453535           3628   \n1                     0               86            1016            284   \n2                     1             1944           28234           1995   \n3                     0                1            1072              0   \n4                     0            13957           25311          10841   \n...                 ...              ...             ...            ...   \n353964                0               34            1509             55   \n353965                0               89           11166            127   \n353966                0             1888             712           3086   \n353967                0              139             486            320   \n353968                0                0              82             24   \n\n                             urls  verified hashtags  url_count  \\\n0                              []         0       []          0   \n1                              []         0       []          0   \n2                              []         0       []          0   \n3       [https://t.co/rytlted08g]         0       []          1   \n4                              []         0       []          0   \n...                           ...       ...      ...        ...   \n353964  [https://t.co/pma33zhslx]         0       []          1   \n353965                         []         0       []          0   \n353966                         []         0       []          0   \n353967                         []         0       []          0   \n353968                         []         0       []          0   \n\n        hashtag_count  tm_year  tm_mon  tm_mday  tm_hour  tm_min  tm_sec  \\\n0                   0     2022       3       11        6      54       8   \n1                   0     2022       3       19       13      51      28   \n2                   0     2022       3       15       19      47      28   \n3                   0     2022       3       14       12      11      22   \n4                   0     2022       3       14       12      46      14   \n...               ...      ...     ...      ...      ...     ...     ...   \n353964              0     2022       3       16       14      42      33   \n353965              0     2022       3       12        9       1      46   \n353966              0     2022       3       18       13      40      30   \n353967              0     2022       3       11        9      26      35   \n353968              0     2022       3       18       12      27      23   \n\n        tm_wday  tm_yday  tm_isdst  \n0             4       70        -1  \n1             5       78        -1  \n2             1       74        -1  \n3             0       73        -1  \n4             0       73        -1  \n...         ...      ...       ...  \n353964        2       75        -1  \n353965        5       71        -1  \n353966        4       77        -1  \n353967        4       70        -1  \n353968        4       77        -1  \n\n[353969 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>retweets_count</th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>urls</th>\n      <th>verified</th>\n      <th>hashtags</th>\n      <th>url_count</th>\n      <th>hashtag_count</th>\n      <th>tm_year</th>\n      <th>tm_mon</th>\n      <th>tm_mday</th>\n      <th>tm_hour</th>\n      <th>tm_min</th>\n      <th>tm_sec</th>\n      <th>tm_wday</th>\n      <th>tm_yday</th>\n      <th>tm_isdst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[rt, refarcir, macron, ans, nom, prépare]</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>11</td>\n      <td>6</td>\n      <td>54</td>\n      <td>8</td>\n      <td>4</td>\n      <td>70</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[populaire]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>19</td>\n      <td>13</td>\n      <td>51</td>\n      <td>28</td>\n      <td>5</td>\n      <td>78</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[faut, dégager, cinglé]</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>15</td>\n      <td>19</td>\n      <td>47</td>\n      <td>28</td>\n      <td>1</td>\n      <td>74</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[enseignants, mettre, prescriptions, président...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>[https://t.co/rytlted08g]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>14</td>\n      <td>12</td>\n      <td>11</td>\n      <td>22</td>\n      <td>0</td>\n      <td>73</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[mafieuse, oppressive, macron]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>14</td>\n      <td>12</td>\n      <td>46</td>\n      <td>14</td>\n      <td>0</td>\n      <td>73</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>353964</th>\n      <td>[gonflette, tour, raciste, frustré]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>34</td>\n      <td>1509</td>\n      <td>55</td>\n      <td>[https://t.co/pma33zhslx]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>16</td>\n      <td>14</td>\n      <td>42</td>\n      <td>33</td>\n      <td>2</td>\n      <td>75</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353965</th>\n      <td>[france, caste, crapuleuse, encadrée, gangster...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>89</td>\n      <td>11166</td>\n      <td>127</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>12</td>\n      <td>9</td>\n      <td>1</td>\n      <td>46</td>\n      <td>5</td>\n      <td>71</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353966</th>\n      <td>[eric, zemmour, français, berbère]</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1888</td>\n      <td>712</td>\n      <td>3086</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>18</td>\n      <td>13</td>\n      <td>40</td>\n      <td>30</td>\n      <td>4</td>\n      <td>77</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353967</th>\n      <td>[gauchistes, dépression, pq]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>139</td>\n      <td>486</td>\n      <td>320</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>11</td>\n      <td>9</td>\n      <td>26</td>\n      <td>35</td>\n      <td>4</td>\n      <td>70</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353968</th>\n      <td>[algérie, emmanuel, macron, grande, histoire, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>82</td>\n      <td>24</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>18</td>\n      <td>12</td>\n      <td>27</td>\n      <td>23</td>\n      <td>4</td>\n      <td>77</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>353969 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        favorites_count  followers_count  statuses_count  friends_count  \\\n0                     0             3682          453535           3628   \n1                     0               86            1016            284   \n2                     1             1944           28234           1995   \n3                     0                1            1072              0   \n4                     0            13957           25311          10841   \n...                 ...              ...             ...            ...   \n353964                0               34            1509             55   \n353965                0               89           11166            127   \n353966                0             1888             712           3086   \n353967                0              139             486            320   \n353968                0                0              82             24   \n\n        verified  url_count  hashtag_count  tm_year  tm_mon  tm_mday  tm_hour  \\\n0              0          0              0     2022       3       11        6   \n1              0          0              0     2022       3       19       13   \n2              0          0              0     2022       3       15       19   \n3              0          1              0     2022       3       14       12   \n4              0          0              0     2022       3       14       12   \n...          ...        ...            ...      ...     ...      ...      ...   \n353964         0          1              0     2022       3       16       14   \n353965         0          0              0     2022       3       12        9   \n353966         0          0              0     2022       3       18       13   \n353967         0          0              0     2022       3       11        9   \n353968         0          0              0     2022       3       18       12   \n\n        tm_min  tm_sec  tm_wday  tm_yday  tm_isdst  \n0           54       8        4       70        -1  \n1           51      28        5       78        -1  \n2           47      28        1       74        -1  \n3           11      22        0       73        -1  \n4           46      14        0       73        -1  \n...        ...     ...      ...      ...       ...  \n353964      42      33        2       75        -1  \n353965       1      46        5       71        -1  \n353966      40      30        4       77        -1  \n353967      26      35        4       70        -1  \n353968      27      23        4       77        -1  \n\n[353969 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>favorites_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>friends_count</th>\n      <th>verified</th>\n      <th>url_count</th>\n      <th>hashtag_count</th>\n      <th>tm_year</th>\n      <th>tm_mon</th>\n      <th>tm_mday</th>\n      <th>tm_hour</th>\n      <th>tm_min</th>\n      <th>tm_sec</th>\n      <th>tm_wday</th>\n      <th>tm_yday</th>\n      <th>tm_isdst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3682</td>\n      <td>453535</td>\n      <td>3628</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>11</td>\n      <td>6</td>\n      <td>54</td>\n      <td>8</td>\n      <td>4</td>\n      <td>70</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86</td>\n      <td>1016</td>\n      <td>284</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>19</td>\n      <td>13</td>\n      <td>51</td>\n      <td>28</td>\n      <td>5</td>\n      <td>78</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1944</td>\n      <td>28234</td>\n      <td>1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>15</td>\n      <td>19</td>\n      <td>47</td>\n      <td>28</td>\n      <td>1</td>\n      <td>74</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1072</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>14</td>\n      <td>12</td>\n      <td>11</td>\n      <td>22</td>\n      <td>0</td>\n      <td>73</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>13957</td>\n      <td>25311</td>\n      <td>10841</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>14</td>\n      <td>12</td>\n      <td>46</td>\n      <td>14</td>\n      <td>0</td>\n      <td>73</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>353964</th>\n      <td>0</td>\n      <td>34</td>\n      <td>1509</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>16</td>\n      <td>14</td>\n      <td>42</td>\n      <td>33</td>\n      <td>2</td>\n      <td>75</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353965</th>\n      <td>0</td>\n      <td>89</td>\n      <td>11166</td>\n      <td>127</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>12</td>\n      <td>9</td>\n      <td>1</td>\n      <td>46</td>\n      <td>5</td>\n      <td>71</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353966</th>\n      <td>0</td>\n      <td>1888</td>\n      <td>712</td>\n      <td>3086</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>18</td>\n      <td>13</td>\n      <td>40</td>\n      <td>30</td>\n      <td>4</td>\n      <td>77</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353967</th>\n      <td>0</td>\n      <td>139</td>\n      <td>486</td>\n      <td>320</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>11</td>\n      <td>9</td>\n      <td>26</td>\n      <td>35</td>\n      <td>4</td>\n      <td>70</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>353968</th>\n      <td>0</td>\n      <td>0</td>\n      <td>82</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2022</td>\n      <td>3</td>\n      <td>18</td>\n      <td>12</td>\n      <td>27</td>\n      <td>23</td>\n      <td>4</td>\n      <td>77</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>353969 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_input = train_df.drop(['retweets_count', 'text', 'urls', 'hashtags'], axis=1)\n",
    "train_df_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=xgboost.XGBRegressor()):\n",
    "    score = sklearn.model_selection.cross_val_score(\n",
    "        model, X, y, cv=5, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    score = - score.mean()\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m baseline_score \u001B[38;5;241m=\u001B[39m \u001B[43mscore_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df_input\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mretweets_count\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBaseline score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbaseline_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m MAE\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn [10], line 2\u001B[0m, in \u001B[0;36mscore_dataset\u001B[1;34m(X, y, model)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscore_dataset\u001B[39m(X, y, model\u001B[38;5;241m=\u001B[39mxgboost\u001B[38;5;241m.\u001B[39mXGBRegressor()):\n\u001B[1;32m----> 2\u001B[0m     score \u001B[38;5;241m=\u001B[39m \u001B[43msklearn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_selection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mneg_mean_absolute_error\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m score\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1040\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[0;32m   1046\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[0;32m   1047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1048\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1049\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    781\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 782\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 686\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\core.py:506\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    505\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 506\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\sklearn.py:789\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m    786\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    788\u001B[0m model, feval, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, eval_metric, params)\n\u001B[1;32m--> 789\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\training.py:188\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(params, dtrain, num_boost_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, evals\u001B[38;5;241m=\u001B[39m(), obj\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, feval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    116\u001B[0m           maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, evals_result\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    117\u001B[0m           verbose_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, xgb_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001B[39;00m\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;124;03m\"\"\"Train a booster with given parameters.\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;124;03m    Booster : a trained booster model\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 188\u001B[0m     bst \u001B[38;5;241m=\u001B[39m \u001B[43m_train_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_boost_round\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxgb_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bst\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\training.py:81\u001B[0m, in \u001B[0;36m_train_internal\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 81\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\xgboost\\core.py:1680\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1677\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_features(dtrain)\n\u001B[0;32m   1679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1680\u001B[0m     _check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1681\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1682\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1684\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "baseline_score = score_dataset(train_df_input.values, train_df['retweets_count'].values)\n",
    "print(f'Baseline score: {baseline_score:.5f} MAE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization, Feature Engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discrete_features = train_df_input.columns == 'verified'\n",
    "\n",
    "mi_scores = sklearn.feature_selection.mutual_info_regression(train_df_input, train_df['retweets_count'], discrete_features=discrete_features)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=train_df_input.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "mi_scores = mi_scores.sort_values(ascending=True)\n",
    "width = np.arange(len(mi_scores))\n",
    "ticks = list(mi_scores.index)\n",
    "plt.barh(width, mi_scores)\n",
    "plt.yticks(width, ticks)\n",
    "plt.title(\"Mutual Information Scores\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_train_df = train_df_input.drop(['tm_sec', 'tm_isdst'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_score = score_dataset(new_train_df.values, train_df['retweets_count'].values)\n",
    "print(f'Baseline score: {baseline_score:.5f} MAE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2)\n",
    "\n",
    "sbn.kdeplot(ax=ax[0, 0], data=train_df.favorites_count)\n",
    "sbn.kdeplot(ax=ax[0, 1], data=np.log10(train_df.favorites_count).replace([-np.inf], -10))\n",
    "sbn.kdeplot(ax=ax[1, 0], data=train_df.friends_count)\n",
    "sbn.kdeplot(ax=ax[1, 1], data=np.log10(train_df.friends_count).replace([-np.inf], -10))\n",
    "sbn.kdeplot(ax=ax[2, 0], data=train_df.followers_count)\n",
    "sbn.kdeplot(ax=ax[2, 1], data=np.log10(train_df.followers_count).replace([-np.inf], -10))\n",
    "sbn.kdeplot(ax=ax[3, 0], data=train_df.statuses_count)\n",
    "sbn.kdeplot(ax=ax[3, 1], data=np.log10(train_df.statuses_count).replace([-np.inf], -10))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_train_df.favorites_count = np.log10(train_df_input.favorites_count).replace([-np.inf], -10)\n",
    "new_train_df.friends_count = np.log10(train_df_input.friends_count).replace([-np.inf], -10)\n",
    "new_train_df.followers_count = np.log10(train_df_input.followers_count).replace([-np.inf], -10)\n",
    "new_train_df.statuses_count = np.log10(train_df_input.statuses_count).replace([-np.inf], -10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_score = score_dataset(new_train_df.values, train_df['retweets_count'].values)\n",
    "print(f'Baseline score: {baseline_score:.5f} MAE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(new_train_df)\n",
    "\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=9, random_state=0).fit(scaler.transform(new_train_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    mean_rtwts = train_df[kmeans.labels_ == i]['retweets_count'].mean()\n",
    "    print(f'Cluster {i} mean retweets: {mean_rtwts}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_train_df['cluster'] = kmeans.labels_\n",
    "new_train_df['cluster'] = new_train_df['cluster'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_score = score_dataset(new_train_df.values, train_df['retweets_count'].values)\n",
    "print(f'Baseline score: {baseline_score:.5f} MAE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hashtags_temp = train_df.explode('hashtags')[['hashtags', 'retweets_count']].groupby('hashtags').mean()\n",
    "hashtags_temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retweet_hash_avg = hashtags_temp.to_dict()['retweets_count']\n",
    "retweet_hash_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_list_avg(list_obj):\n",
    "    sum = 0\n",
    "    for hash in list_obj:\n",
    "        sum += retweet_hash_avg[hash] if hash in retweet_hash_avg else -1.0\n",
    "    return sum / len(list_obj) if list_obj else -1.0\n",
    "\n",
    "new_train_df['retweet_hash_avg'] = train_df['hashtags'].apply(get_list_avg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_score = score_dataset(new_train_df.values, train_df['retweets_count'].values)\n",
    "print(f'Baseline score: {baseline_score:.5f} MAE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_hashs = test_df.explode('hashtags')['hashtags'].unique()[1:]\n",
    "sum = 0\n",
    "for i in range(len(test_hashs)):\n",
    "    if test_hashs[i] in retweet_hash_avg:\n",
    "        sum += 1\n",
    "print(sum, len(test_hashs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame, type: str = 'train'):\n",
    "    final_df = df.drop(['text', 'urls', 'hashtags', 'tm_sec', 'tm_isdst'], axis=1)\n",
    "    if type == 'train':\n",
    "        final_df = final_df.drop('retweets_count', axis=1)\n",
    "\n",
    "    def has_rt(word_list):\n",
    "        return int('rt' in word_list)\n",
    "    final_df['has_rt'] = df['text'].apply(has_rt)\n",
    "\n",
    "    return final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_X = feature_engineering(train_df)\n",
    "train_y = train_df['retweets_count']\n",
    "test_X = feature_engineering(test_df, type='test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_X.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "nlp_model = gensim.models.Word2Vec.load('models/word2vec.model')\n",
    "\n",
    "train_tweets = read_train_df['text'].apply(str.split).to_list()\n",
    "train_dictionary = gensim.corpora.Dictionary(train_tweets)\n",
    "train_corpus = [train_dictionary.doc2bow(tweet) for tweet in train_tweets]\n",
    "\n",
    "tfidf = gensim.models.TfidfModel(train_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.4847324 , -0.70134666,  0.12469119, ...,  0.01117111,\n        -0.41192005,  0.24063279],\n       [ 0.45623055, -0.18246764,  0.70864767, ..., -0.3881304 ,\n        -1.30220354,  0.56361079],\n       [ 0.15627581, -0.80873431,  0.37365898, ..., -0.01091827,\n        -0.05623215,  0.45437797],\n       ...,\n       [-0.09304367,  0.01267988,  0.31910956, ...,  0.45147368,\n        -1.33754551,  0.49690839],\n       [ 0.24135732, -0.57199737,  0.04274321, ..., -0.3322872 ,\n        -1.13280275,  0.2263712 ],\n       [-0.51508811, -0.71377925,  0.86331788, ..., -0.11672507,\n        -0.78853706,  0.86969074]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = read_train_df['text']\n",
    "\n",
    "text_embed = np.zeros((len(text), nlp_model.vector_size))\n",
    "\n",
    "for i in range(len(text)):\n",
    "    encoded_words = [word for word in text.iloc[i].split(' ') if word in nlp_model.wv and\n",
    "                     word in train_dictionary.token2id]\n",
    "    if encoded_words:\n",
    "        keys = [train_dictionary.token2id[word] for word in encoded_words]\n",
    "        tf_idf_dict = dict(tfidf[train_corpus[i]])\n",
    "        tf_idf_coefs = np.array([tf_idf_dict[key] for key in keys])\n",
    "\n",
    "        text_vec = nlp_model.wv[encoded_words]\n",
    "        text_vec = (text_vec * tf_idf_coefs[:, None]).sum(0)\n",
    "    else:\n",
    "        text_vec = np.zeros((nlp_model.vector_size, ))\n",
    "\n",
    "    text_embed[i] = text_vec\n",
    "\n",
    "text_embed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from models.conv1d_w2v_mlp import ConvWord2VecModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "ConvWord2VecModel(\n  (conv): Sequential(\n    (0): Conv1d(1, 16, kernel_size=(5,), stride=(1,))\n    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Dropout(p=0.3, inplace=False)\n    (5): Conv1d(16, 16, kernel_size=(5,), stride=(2,))\n    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): ReLU()\n    (8): Dropout(p=0.3, inplace=False)\n    (9): Conv1d(16, 64, kernel_size=(5,), stride=(1,))\n    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU()\n    (12): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (13): Dropout(p=0.3, inplace=False)\n    (14): Conv1d(64, 64, kernel_size=(5,), stride=(2,))\n    (15): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU()\n    (17): Dropout(p=0.3, inplace=False)\n    (18): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n    (19): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU()\n    (21): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Dropout(p=0.3, inplace=False)\n    (23): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n    (24): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU()\n    (26): Conv1d(128, 4, kernel_size=(1,), stride=(1,))\n    (27): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (28): Flatten(start_dim=1, end_dim=-1)\n  )\n  (input): Linear(in_features=23, out_features=128, bias=True)\n  (hidden_layers): Sequential(\n    (layer1): Linear(in_features=128, out_features=128, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.3, inplace=False)\n    (layer2): Linear(in_features=128, out_features=128, bias=True)\n    (relu2): ReLU()\n    (dropout2): Dropout(p=0.3, inplace=False)\n  )\n  (output): Linear(in_features=128, out_features=1, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = ConvWord2VecModel.load_from_checkpoint('checkpoints/Conv2_to8_W2V_256_tfidf_MLP_15fts_4_128_LR1e-3cosine72etaMin5e-5_AdamW_dropout0.3_hasRT_CV/checkpoints/epoch=62-split=0.ckpt')\n",
    "conv_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('lightning_logs/model_architecture')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "kf = sklearn.model_selection.KFold(n_splits=10, shuffle=True, random_state=12345)\n",
    "all_splits = [i for i in kf.split(train_X)]\n",
    "train_indexes, val_indexes = all_splits[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train_X_arr = train_X.values\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "train_X_arr = scaler.fit_transform(train_X_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "train_X_arr = np.concatenate([train_X_arr, text_embed], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "input_dict = (torch.tensor(train_X_arr[val_indexes]), torch.tensor(train_y.values[val_indexes]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caioj\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\_jit_internal.py:668: LightningDeprecationWarning: The `LightningModule.model_size` property was deprecated in v1.5 and will be removed in v1.7. Please use the `pytorch_lightning.utilities.memory.get_model_size_mb`.\n",
      "  if hasattr(mod, name):\n",
      "C:\\Users\\caioj\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\_jit_internal.py:669: LightningDeprecationWarning: The `LightningModule.model_size` property was deprecated in v1.5 and will be removed in v1.7. Please use the `pytorch_lightning.utilities.memory.get_model_size_mb`.\n",
      "  item = getattr(mod, name)\n",
      "C:\\Users\\caioj\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\_jit_internal.py:668: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  if hasattr(mod, name):\n",
      "C:\\Users\\caioj\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\_jit_internal.py:669: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  item = getattr(mod, name)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwriter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconv_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m writer\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:736\u001B[0m, in \u001B[0;36mSummaryWriter.add_graph\u001B[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001B[0m\n\u001B[0;32m    733\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_once(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorboard.logging.add_graph\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001B[39;00m\n\u001B[1;32m--> 736\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_file_writer()\u001B[38;5;241m.\u001B[39madd_graph(\u001B[43mgraph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_to_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_strict_trace\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    737\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001B[39;00m\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcaffe2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m caffe2_pb2\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:289\u001B[0m, in \u001B[0;36mgraph\u001B[1;34m(model, args, verbose, use_strict_trace)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mselect_model_mode_for_export(model, torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mTrainingMode\u001B[38;5;241m.\u001B[39mEVAL):  \u001B[38;5;66;03m# TODO: move outside of torch.onnx?\u001B[39;00m\n\u001B[0;32m    288\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 289\u001B[0m         trace \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_strict_trace\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    290\u001B[0m         graph \u001B[38;5;241m=\u001B[39m trace\u001B[38;5;241m.\u001B[39mgraph\n\u001B[0;32m    291\u001B[0m         torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_jit_pass_inline(graph)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\jit\\_trace.py:741\u001B[0m, in \u001B[0;36mtrace\u001B[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func\n\u001B[0;32m    740\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[1;32m--> 741\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrace_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    743\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_trace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrap_check_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheck_inputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_tolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    748\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    749\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_module_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    754\u001B[0m     \u001B[38;5;28mhasattr\u001B[39m(func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__self__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule)\n\u001B[0;32m    756\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    757\u001B[0m ):\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trace_module(\n\u001B[0;32m    759\u001B[0m         func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[0;32m    760\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m: example_inputs},\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    767\u001B[0m         _module_class,\n\u001B[0;32m    768\u001B[0m     )\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\jit\\_trace.py:958\u001B[0m, in \u001B[0;36mtrace_module\u001B[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[0;32m    954\u001B[0m     argument_names \u001B[38;5;241m=\u001B[39m get_callable_argument_names(func)\n\u001B[0;32m    956\u001B[0m example_inputs \u001B[38;5;241m=\u001B[39m make_tuple(example_inputs)\n\u001B[1;32m--> 958\u001B[0m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_method_from_trace\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvar_lookup_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    963\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43margument_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    967\u001B[0m check_trace_method \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_c\u001B[38;5;241m.\u001B[39m_get_method(method_name)\n\u001B[0;32m    969\u001B[0m \u001B[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\forest-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1090\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1088\u001B[0m         recording_scopes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1089\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1090\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "writer.add_graph(conv_model, input_dict)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_results = conv_model(input_dict).detach().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.stem(np.abs(val_results - train_y.values[val_indexes]))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.abs(val_results - train_y.values[val_indexes]).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_analysis = train_df.iloc[val_indexes][['text', 'retweets_count']]\n",
    "val_analysis['predictions'] = val_results\n",
    "val_analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_submission = True\n",
    "\n",
    "if make_submission:\n",
    "    test_ids = read_train_df['TweetID'].iloc[val_indexes]\n",
    "    # model = xgboost.XGBRegressor(verbosity=1, max_depth=10)\n",
    "    # model.fit(full_train_X, train_y)\n",
    "    #\n",
    "    # test_predictions = model.predict(full_test_X)\n",
    "\n",
    "    submission_df = pd.DataFrame(data={'TweetID': test_ids, 'retweets_count': val_results})\n",
    "    submission_df.to_csv('data/val_predictions.csv', index=False)\n",
    "\n",
    "    print('Saved csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
